1. 머신러닝은 지도학습과 비지도학습으로 나뉜다

1-1 지도학습 
   
    - 입력과 출력 데이터 쌍이 필요
    - 임의의 입력이 들어오면 어떤 출력을 할지 예측

1-2 비지도학습
    
    - 출력 데이터가 필요 없음
    - 입력 데이터만 가지고서 어떤 특징이나 경향을 추정
    - 상대적으로 비지도학습은 지도학습의 데이터 전처리 과정에서 많이 사용


2. 학습데이터, 시험데이터, 과적합

2-1 머신러닝의 가장 큰 문제점은 과적합(overfitting)

2-2 해결책은 데이터의 일부만 사용해서 학습을 하면서 그 성능을 나머지 데이터로 검증하는 것
        
    (1) 데이터를 무작위로 학습셋과 시험셋으로 나누기
    (2) k겹 교차검증
      (전체 데이터를 k개로 나누고 k-1개 데이터로 학습을 하고 나머지 1개로 검증, 계속 다른 k-1개를 골라서 총 k번 반복)
    (3) 데이터를 학습셋, 시험셋, 검증셋으로 나누고, 모든 학습이 끝난 뒤 검증셋을 최종 성능 평가에만 사용
    
3. 특징값 추출

    - 머신러닝으로 의미 있는 결과를 얻으려면 특징값 추출을 잘해야 한다. 데이터와 배경지식을 공부할수록 좋은 특징값을
    찾을 수 있지만 배경지식을 끝없이 공부할 수는 없기 때문
    
    - 일반적인 특징값 = is_null, 모조 변수, 순위, 비닝, 로그 함수
    
4. 분류기

    - 머신러닝 분류기는 대체로 어떤 특징값이 쓸모가 있는지를 학습
    - 분류기의 성능으 두가지 잣대로 평가. 원하는 것을 얼마나 잘 찾나, 원하지 않는 것을 얼마나 잘 걸러내는가.
      (참 양성비, 거짓 양성비를 이용하여 평가하면 됨)

4-1 랜덤포레스트

    - 각각 다른 학습데이터를 이용해 학습한 결정 트리를 모아놓은 분류기
    - 예측은 여러 결정 트리의 평균 예측값을 사용
    - 설령 과적합이 발생하더라도 트리마다 다른 과적합이 일어나는데 이것 역시 여러 트리를 모으면 상쇄된다는 원리

4-2 로지스틱 회귀

    - 초평면과 데이터 표본의 거리를 이용해 각 범주에 속할 확률을 구함


4-3 인공신경망

    - 뉴런 하나하나가 회귀의 출력에 해당
    - 은닉계층이 없고 입력계층과 출력계층만 있는 신경망은 로지스틱 회귀를 여러개 합쳐놓은 것과 동일
    - 신경망은 역전파 알고리즘이라는 반복 알고리즘으로 학습


5. ROC 곡선

    - 분류기의 성능을 시각화 하는 곡선
    - 좋은 분류기는 roc커브가 급격하게 증가한다.
    - roc곡선을 요약하는 방법으로 곡선 하단의 면적을 계산하는 auc가 널리 쓰인다.
    - 성능이 좋은 분류기는 곡선이 면적을 거의 꽉 채우기 때문에 auc 값이 1에 가깝다.


  
